
import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs
import datetime
import pandas as pd
import time
import requests
import http.cookiejar
import os

# --- é–¢æ•°å®šç¾© ---
def extract_video_id(url):
    """
    YouTubeã®URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
    """
    if not url:
        return None
    try:
        parsed_url = urlparse(url)
        if parsed_url.hostname == 'youtu.be':
            return parsed_url.path[1:]
        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):
            if parsed_url.path == '/watch':
                p = parse_qs(parsed_url.query)
                return p['v'][0] if 'v' in p else None
            elif parsed_url.path.startswith('/embed/'):
                return parsed_url.path.split('/')[2]
            elif parsed_url.path.startswith('/v/'):
                return parsed_url.path.split('/')[2]
        return None
    except:
        return None

def format_timestamp(seconds):
    """ç§’æ•°ã‚’ HH:MM:SS å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    return str(datetime.timedelta(seconds=int(seconds)))

def fetch_video_title(session, video_id):
    """YouTubeã®ãƒšãƒ¼ã‚¸ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—ã™ã‚‹"""
    try:
        url = f"https://www.youtube.com/watch?v={video_id}"
        response = session.get(url)
        if response.status_code == 200:
            html = response.text
            # <title>ã‚¿ã‚¤ãƒˆãƒ« - YouTube</title> ã‹ã‚‰æŠ½å‡º
            if "<title>" in html:
                start = html.find("<title>") + 7
                end = html.find("</title>")
                title = html[start:end].strip()
                # " - YouTube" ã‚’é™¤å»
                if title.endswith(" - YouTube"):
                    title = title[:-10].strip()
                return title
    except:
        pass
    return f"(ã‚¿ã‚¤ãƒˆãƒ«å–å¾—å¤±æ•—: {video_id})"

def search_transcript(transcript_data, keywords):
    """
    å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢ã—ã€çµæœãƒªã‚¹ãƒˆã‚’è¿”ã™
    ï¼ˆdictå½¢å¼ã¨dataclasså½¢å¼ã®ä¸¡æ–¹ã«å¯¾å¿œï¼‰
    """
    results = []
    for entry in transcript_data:
        # dataclassï¼ˆ.textï¼‰ã¨dictï¼ˆ['text']ï¼‰ã®ä¸¡æ–¹ã«å¯¾å¿œ
        text = entry.text if hasattr(entry, 'text') else entry['text']
        start_time = entry.start if hasattr(entry, 'start') else entry['start']
        
        # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã„ãšã‚Œã‹ãŒå«ã¾ã‚Œã‚‹ã‹ï¼Ÿ (ORæ¤œç´¢)
        hit_keywords = []
        for k in keywords:
            if k.lower() in text.lower():
                hit_keywords.append(k)
        
        if hit_keywords:
            results.append({
                "seconds": start_time,
                "text": text,
                "keywords": hit_keywords
            })
    return results

def get_authenticated_api():
    """
    cookies.txtãŒå­˜åœ¨ã™ã‚‹å ´åˆã€èª­ã¿è¾¼ã‚“ã§èªè¨¼ä»˜ãã®APIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã™
    """
    session = requests.Session()
    # User-Agentã‚’å½è£…ï¼ˆBotåˆ¤å®šå›é¿ã®ãŸã‚é‡è¦ï¼‰
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    })
    cookie_file = 'cookies.txt'
    
    if os.path.exists(cookie_file):
        try:
            cookie_jar = http.cookiejar.MozillaCookieJar(cookie_file)
            cookie_jar.load(ignore_discard=True, ignore_expires=True)
            session.cookies = cookie_jar
            st.sidebar.success(f"âœ… cookies.txt ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ ({len(cookie_jar)} cookies loaded)")
            
            # ãƒ‡ãƒãƒƒã‚°: èª­ã¿è¾¼ã‚“ã Cookieã®å†…è¨³ã‚’è¡¨ç¤º
            cookie_preview = []
            for cookie in cookie_jar:
                if "youtube" in cookie.domain:
                    cookie_preview.append(f"{cookie.domain}: {cookie.name}")
            
            if cookie_preview:
                with st.sidebar.expander("èª­ã¿è¾¼ã‚“ã YouTube Cookie"):
                    st.sidebar.code("\n".join(cookie_preview))
            else:
                 st.sidebar.warning("âš ï¸ YouTubeé–¢é€£ã®CookieãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.sidebar.error(f"âŒ cookies.txt ã®èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            st.sidebar.warning("â€» Netscapeå½¢å¼ã® cookies.txt ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
            return YouTubeTranscriptApi() 
    else:
        st.sidebar.warning("âš ï¸ cookies.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.sidebar.caption("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ç›´ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
            
    # http_clientã¨ã—ã¦sessionã‚’æ¸¡ã™
    return YouTubeTranscriptApi(http_client=session)

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="YouTube Keyword Search V2",
    page_icon="ğŸ”",
    layout="wide"
)

# --- UIå®Ÿè£… ---
st.title("ğŸ“º YouTubeå­—å¹•æ¤œç´¢ã‚¢ãƒ—ãƒª V2")
st.write("è¤‡æ•°ã®å‹•ç”»ã‹ã‚‰ã€è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ã¦æ¤œç´¢ã§ãã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("ä½¿ã„æ–¹")
    st.markdown("""
    1. **å‹•ç”»URL**: 1è¡Œã«1ã¤ãšã¤å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
    2. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: ã‚«ãƒ³ãƒ(,)ã¾ãŸã¯ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
    3. **æ¤œç´¢**: ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
    4. **ä¿å­˜**: çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
    """)
    st.info("â€» å­—å¹•ãŒãªã„å‹•ç”»ã‚„ã€ç„¡åŠ¹ãªURLã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")
    
    # Cookieæƒ…å ±ã®è¡¨ç¤º
    if os.path.exists('cookies.txt'):
         st.caption("â„¹ï¸ Cookieèªè¨¼ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œä¸­")

# ãƒ¡ã‚¤ãƒ³å…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆ2ã‚«ãƒ©ãƒ ï¼‰
col1, col2 = st.columns(2)

with col1:
    url_input_raw = st.text_area(
        "YouTubeå‹•ç”»ã®URLï¼ˆè¤‡æ•°å¯ãƒ»æ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰",
        value="https://www.youtube.com/watch?v=j9YpkSX7NNM",
        placeholder="https://www.youtube.com/watch?v=...\nhttps://www.youtube.com/watch?v=...",
        height=200
    )

with col2:
    keyword_input_raw = st.text_input(
        "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ãƒ»ã‚«ãƒ³ãƒ/ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰",
        value="Python, AI",
        placeholder="ä¾‹: AI, Python, æ©Ÿæ¢°å­¦ç¿’"
    )

# æ¤œç´¢ãƒœã‚¿ãƒ³
if st.button("æ¤œç´¢é–‹å§‹ ğŸš€", type="primary", use_container_width=True):
    # 1. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢
    urls = [line.strip() for line in url_input_raw.split('\n') if line.strip()]
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²ï¼ˆã‚«ãƒ³ãƒã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®æ› -> splitï¼‰
    keywords_raw = keyword_input_raw.replace('ã€', ' ').replace(',', ' ')
    keywords = [k.strip() for k in keywords_raw.split() if k.strip()]

    # 2. ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not urls:
        st.error("âš ï¸ YouTubeã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not keywords:
        st.error("âš ï¸ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        # 3. æ¤œç´¢å‡¦ç†å®Ÿè¡Œ
        results_data = [] # æœ€çµ‚çš„ãªè¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # APIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—ï¼ˆCookieå¯¾å¿œï¼‰
        api_obj = get_authenticated_api()
        
        total_urls = len(urls)
        
        for i, url in enumerate(urls):
            current_progress = (i) / total_urls
            progress_bar.progress(current_progress)
            
            video_id = extract_video_id(url)
            
            if not video_id:
                st.toast(f"ã‚¹ã‚­ãƒƒãƒ— (ç„¡åŠ¹ãªURL): {url}", icon="â­ï¸")
                continue
            
            status_text.text(f"æ¤œç´¢ä¸­ ({i+1}/{total_urls}): {video_id}")
            
            try:
                # å­—å¹•å–å¾—
                transcript_list = api_obj.list(video_id)
                try:
                     transcript = transcript_list.find_transcript(['ja', 'en', 'en-US'])
                except:
                     transcript = transcript_list.find_transcript(['ja', 'en']) 

                transcript_data = transcript.fetch()
                
                # ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ï¼ˆAPIã§ä½¿ã£ãŸsessionã‚’å†åˆ©ç”¨ï¼‰
                video_title = fetch_video_title(api_obj._fetcher._http_client, video_id)
                
                # æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯å‘¼ã³å‡ºã—
                found_entries = search_transcript(transcript_data, keywords)
                
                # çµæœè¿½åŠ 
                for res in found_entries:
                    start_time = res['seconds']
                    text = res['text']
                    hit_keywords = res['keywords']
                    
                    formatted_time = format_timestamp(start_time)
                    link_url = f"https://youtu.be/{video_id}?t={int(start_time)}"
                    
                    results_data.append({
                        "Title": video_title,
                        "Video ID": video_id,
                        "Original URL": url,
                        "Keyword": ", ".join(hit_keywords),
                        "Time": formatted_time,
                        "Text": text,
                        "Link": link_url,
                        "Seconds": start_time
                    })
                        
            except Exception as e:
                st.error(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ ({video_id}): å­—å¹•ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\nç†ç”±: {e}")
        
        # å®Œäº†å‡¦ç†
        progress_bar.progress(1.0)
        status_text.text("å®Œäº†ï¼")
        time.sleep(0.5)
        status_text.empty()
        progress_bar.empty()
        
        # 4. çµæœè¡¨ç¤º
        if results_data:
            df = pd.DataFrame(results_data)
            
            st.success(f"ğŸ‰ æ¤œç´¢å®Œäº†: åˆè¨ˆ {len(df)} ä»¶ ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸï¼")
            
            tab1, tab2 = st.tabs(["ğŸ“‹ ãƒªã‚¹ãƒˆè¡¨ç¤º", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"])
            
            with tab1:
                for index, row in df.iterrows():
                    with st.container():
                        st.markdown(f"**ğŸ¬ {row['Title']}**")
                        st.markdown(f"### {row['Time']} (Keyword: {row['Keyword']})")
                        st.markdown(f"[{row['Text']}]({row['Link']})")
                        st.divider()

            with tab2:
                st.dataframe(
                    df[['Title', 'Keyword', 'Time', 'Text', 'Link', 'Original URL']],
                    column_config={
                        "Title": st.column_config.TextColumn("ã‚¿ã‚¤ãƒˆãƒ«"),
                        "Link": st.column_config.LinkColumn("å†ç”Ÿãƒªãƒ³ã‚¯", display_text="å†ç”Ÿ â–¶ï¸"),
                        "Original URL": st.column_config.LinkColumn("å‹•ç”»URL")
                    },
                    use_container_width=True,
                    hide_index=True
                )
            
            csv_data = df.to_csv(index=False).encode('utf-8-sig')
            
            st.download_button(
                label="ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=f"youtube_search_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                type="primary"
            )
            
        else:
            st.warning("æŒ‡å®šã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


import streamlit as st
from youtube_transcript_api import YouTubeTranscriptApi
from urllib.parse import urlparse, parse_qs
import datetime
import pandas as pd
import time

# --- é–¢æ•°å®šç¾© ---
def extract_video_id(url):
    """
    YouTubeã®URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
    """
    if not url:
        return None
    try:
        parsed_url = urlparse(url)
        if parsed_url.hostname == 'youtu.be':
            return parsed_url.path[1:]
        if parsed_url.hostname in ('www.youtube.com', 'youtube.com'):
            if parsed_url.path == '/watch':
                p = parse_qs(parsed_url.query)
                return p['v'][0] if 'v' in p else None
            elif parsed_url.path.startswith('/embed/'):
                return parsed_url.path.split('/')[2]
            elif parsed_url.path.startswith('/v/'):
                return parsed_url.path.split('/')[2]
        return None
    except:
        return None

def format_timestamp(seconds):
    """ç§’æ•°ã‚’ HH:MM:SS å½¢å¼ã«å¤‰æ›ã™ã‚‹"""
    return str(datetime.timedelta(seconds=int(seconds)))

def search_transcript(transcript_data, keywords):
    """
    å­—å¹•ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢ã—ã€çµæœãƒªã‚¹ãƒˆã‚’è¿”ã™
    """
    results = []
    for entry in transcript_data:
        text = entry['text']
        start_time = entry['start']
        
        # è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã„ãšã‚Œã‹ãŒå«ã¾ã‚Œã‚‹ã‹ï¼Ÿ (ORæ¤œç´¢)
        hit_keywords = []
        for k in keywords:
            if k.lower() in text.lower():
                hit_keywords.append(k)
        
        if hit_keywords:
            results.append({
                "seconds": start_time,
                "text": text,
                "keywords": hit_keywords
            })
    return results

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="YouTube Keyword Search V2",
    page_icon="ğŸ”",
    layout="wide"
)

# --- UIå®Ÿè£… ---
st.title("ğŸ“º YouTubeå­—å¹•æ¤œç´¢ã‚¢ãƒ—ãƒª V2")
st.write("è¤‡æ•°ã®å‹•ç”»ã‹ã‚‰ã€è¤‡æ•°ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ã¦æ¤œç´¢ã§ãã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("ä½¿ã„æ–¹")
    st.markdown("""
    1. **å‹•ç”»URL**: 1è¡Œã«1ã¤ãšã¤å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
    2. **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: ã‚«ãƒ³ãƒ(,)ã¾ãŸã¯ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚
    3. **æ¤œç´¢**: ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
    4. **ä¿å­˜**: çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
    """)
    st.info("â€» å­—å¹•ãŒãªã„å‹•ç”»ã‚„ã€ç„¡åŠ¹ãªURLã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")

# ãƒ¡ã‚¤ãƒ³å…¥åŠ›ã‚¨ãƒªã‚¢ï¼ˆ2ã‚«ãƒ©ãƒ ï¼‰
col1, col2 = st.columns(2)

with col1:
    url_input_raw = st.text_area(
        "YouTubeå‹•ç”»ã®URLï¼ˆè¤‡æ•°å¯ãƒ»æ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰",
        value="https://www.youtube.com/watch?v=j9YpkSX7NNM",
        placeholder="https://www.youtube.com/watch?v=...\nhttps://www.youtube.com/watch?v=...",
        height=200
    )

with col2:
    keyword_input_raw = st.text_input(
        "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°å¯ãƒ»ã‚«ãƒ³ãƒ/ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰",
        value="Python, AI",
        placeholder="ä¾‹: AI, Python, æ©Ÿæ¢°å­¦ç¿’"
    )

# æ¤œç´¢ãƒœã‚¿ãƒ³
if st.button("æ¤œç´¢é–‹å§‹ ğŸš€", type="primary", use_container_width=True):
    # 1. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢
    urls = [line.strip() for line in url_input_raw.split('\n') if line.strip()]
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†å‰²ï¼ˆã‚«ãƒ³ãƒã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®æ› -> splitï¼‰
    keywords_raw = keyword_input_raw.replace('ã€', ' ').replace(',', ' ')
    keywords = [k.strip() for k in keywords_raw.split() if k.strip()]

    # 2. ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not urls:
        st.error("âš ï¸ YouTubeã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    elif not keywords:
        st.error("âš ï¸ æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        # 3. æ¤œç´¢å‡¦ç†å®Ÿè¡Œ
        results_data = [] # æœ€çµ‚çš„ãªè¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        api = YouTubeTranscriptApi()
        total_urls = len(urls)
        
        for i, url in enumerate(urls):
            current_progress = (i) / total_urls
            progress_bar.progress(current_progress)
            
            video_id = extract_video_id(url)
            
            if not video_id:
                st.toast(f"ã‚¹ã‚­ãƒƒãƒ— (ç„¡åŠ¹ãªURL): {url}", icon="â­ï¸")
                continue
            
            status_text.text(f"æ¤œç´¢ä¸­ ({i+1}/{total_urls}): {video_id}")
            
            try:
                # å­—å¹•å–å¾—
                transcript_list = api.list(video_id)
                try:
                     transcript = transcript_list.find_transcript(['ja', 'en', 'en-US'])
                except:
                     transcript = transcript_list.find_transcript(['ja', 'en']) 

                transcript_data = transcript.fetch()
                
                # â˜…ã“ã“ã§æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ã‚’å‘¼ã³å‡ºã—â˜…
                found_entries = search_transcript(transcript_data, keywords)
                
                # çµæœã‚’æ•´å½¢ã—ã¦è¿½åŠ 
                for res in found_entries:
                    start_time = res['seconds']
                    text = res['text']
                    hit_keywords = res['keywords']
                    
                    formatted_time = format_timestamp(start_time)
                    link_url = f"https://youtu.be/{video_id}?t={int(start_time)}"
                    
                    results_data.append({
                        "Video ID": video_id,
                        "Original URL": url,
                        "Keyword": ", ".join(hit_keywords),
                        "Time": formatted_time,
                        "Text": text,
                        "Link": link_url,
                        "Seconds": start_time
                    })
                        
            except Exception as e:
                st.error(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ ({video_id}): å­—å¹•ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\nç†ç”±: {e}")
        
        # å®Œäº†å‡¦ç†
        progress_bar.progress(1.0)
        status_text.text("å®Œäº†ï¼")
        time.sleep(0.5)
        status_text.empty()
        progress_bar.empty()
        
        # 4. çµæœè¡¨ç¤º
        if results_data:
            df = pd.DataFrame(results_data)
            
            st.success(f"ğŸ‰ æ¤œç´¢å®Œäº†: åˆè¨ˆ {len(df)} ä»¶ ãƒ’ãƒƒãƒˆã—ã¾ã—ãŸï¼")
            
            tab1, tab2 = st.tabs(["ğŸ“‹ ãƒªã‚¹ãƒˆè¡¨ç¤º", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«"])
            
            with tab1:
                for index, row in df.iterrows():
                    with st.container():
                        st.markdown(f"### {row['Time']} (Keyword: {row['Keyword']})")
                        st.markdown(f"[{row['Text']}]({row['Link']})")
                        st.divider()

            with tab2:
                st.dataframe(
                    df[['Keyword', 'Time', 'Text', 'Link', 'Original URL']],
                    column_config={
                        "Link": st.column_config.LinkColumn("å†ç”Ÿãƒªãƒ³ã‚¯", display_text="å†ç”Ÿ â–¶ï¸"),
                        "Original URL": st.column_config.LinkColumn("å‹•ç”»URL")
                    },
                    use_container_width=True,
                    hide_index=True
                )
            
            csv_data = df.to_csv(index=False).encode('utf-8-sig')
            
            st.download_button(
                label="ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=f"youtube_search_results_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                type="primary"
            )
            
        else:
            st.warning("æŒ‡å®šã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
